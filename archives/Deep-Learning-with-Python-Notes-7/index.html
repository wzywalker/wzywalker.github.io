<!DOCTYPE HTML>
<html lang="english">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="renderer" content="webkit">
    <meta name="HandheldFriendly" content="true">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Maverick,AlanDecode,Galileo,blog" />
    <meta name="generator" content="Maverick 1.2.1" />
    <meta name="template" content="Prism" />
    <link rel="alternate" type="application/rss+xml" title="walker's code blog &raquo; RSS 2.0" href="/feed/index.xml" />
    <link rel="alternate" type="application/atom+xml" title="walker's code blog &raquo; ATOM 1.0" href="/feed/atom/index.xml" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/prism-b9d78ff38a.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/ExSearch/ExSearch-182e5a8869.css">
    <link href="https://fonts.googleapis.com/css?family=Fira+Code&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css">
    <script>
        var ExSearchConfig = {
            root: "",
            api: "https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/0792c859af00d57f17774077bdd3dbf1.json"
        }

    </script>
    
<title>ã€ŠDeep Learning with Pythonã€‹ç¬”è®°[7] - walker's code blog</title>
<meta name="author" content="walker" />
<meta name="description" content="Generative deep learning" />
<meta property="og:title" content="ã€ŠDeep Learning with Pythonã€‹ç¬”è®°[7] - walker's code blog" />
<meta property="og:description" content="Generative deep learning" />
<meta property="og:site_name" content="walker's code blog" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/archives/Deep-Learning-with-Python-Notes-7/" />
<meta property="og:image" content="" />
<meta property="article:published_time" content="2021-10-12T22:17:00-00.00" />
<meta name="twitter:title" content="ã€ŠDeep Learning with Pythonã€‹ç¬”è®°[7] - walker's code blog" />
<meta name="twitter:description" content="Generative deep learning" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:image" content="" />


    
</head>

<body>
    <div class="container prism-container">
        <header class="prism-header" id="prism__header">
            <h1 class="text-uppercase brand"><a class="no-link" href="/" target="_self">walker's code blog</a></h1>
            <p>coder, reader</p>
            <nav class="prism-nav"><ul><li><a class="no-link text-uppercase " href="/" target="_self">Home</a></li><li><a class="no-link text-uppercase " href="/archives/" target="_self">Archives</a></li><li><a class="no-link text-uppercase " href="/about/" target="_self">About</a></li><li><a href="#" target="_self" class="search-form-input no-link text-uppercase">Search</a></li></ul></nav>
        </header>
        <div class="prism-wrapper" id="prism__wrapper">
            
<main>
    <section class="prism-section row" id="prism__content">
        <article class="yue col-md-8 offset-md-2">
            <h1 class="prism-post-title">ã€ŠDeep Learning with Pythonã€‹ç¬”è®°[7]</h1>
            <div class="prism-post-time">
                <time class="text-uppercase">
                    October 12 2021
                </time>
            </div>
            <div class="prism-content-body">
                <h1>Generative deep learning</h1>
<p>Our perceptual modalities, our language, and our artwork all have <code>statistical structure</code>. Learning this structure is what deep-learning algorithms excel at.</p><p>Machine-learning models can learn the <code>statistical latent space</code> of images, music, and stories, and they can then<code>sample from this space</code>, <strong>creating new artworks</strong> with characteristics similar to those the model has seen in its training data.</p><h2>Text generation with LSTM</h2>
<h3>Language model</h3>
<p>å¾ˆå¤šåœ°æ–¹éƒ½åœ¨æŒ‰è‡ªå·±çš„ç†è§£å®šä¹‰<code>language model</code>ï¼Œè¿™æœ¬ä¹¦å®šä¹‰å¾ˆæ˜ç¡®ï¼Œèƒ½ä¸ºæ ¹æ®å‰æ–‡é¢„æµ‹ä¸‹ä¸€ä¸ªæˆ–å¤šä¸ªtokenå»ºç«‹æ¦‚ç‡æ¨¡å‹çš„ç½‘ç»œã€‚</p><blockquote>
<p>any network that can model the probability of the next token given the previous ones is called a language model.</p></blockquote>
<ol>
<li>æ‰€ä»¥é¦–å…ˆï¼Œå®ƒæ˜¯ä¸€ä¸ªnetwork</li>
<li>å®ƒåšçš„äº‹æ˜¯modelä¸€ä¸ªprobability</li>
<li>å†…å®¹æ˜¯the next token</li>
<li>æ¡ä»¶æ˜¯previous tokens</li>
</ol>
<p>ä¸€æ—¦ä½ æœ‰äº†è¿™æ ·ä¸€ä¸ªlanguage modelï¼Œä½ å°±èƒ½<code>sample from it</code>ï¼Œè¿™å°±æ˜¯å‰é¢ç¬”è®°é‡Œçš„sample from lantent space, ç„¶ågenerateäº†ã€‚</p><h3>greedy sampling and stochastic sampling</h3>
<p>å¦‚æœæ ¹æ®æ¦‚ç‡æ¨¡å‹æ¯æ¬¡éƒ½é€‰â€œæœ€å¯èƒ½â€çš„è¾“å‡ºï¼Œåœ¨è¿è´¯æ€§ä¸Šè¢«è¯æ˜æ˜¯ä¸å¥½çš„ï¼Œè€Œä¸”ä¹Ÿä¸§å¤±äº†åˆ›é€ æ€§ï¼Œæ‰€ä»¥è¿˜æ˜¯ç»™äº†ä¸€å®šçš„éšæœºæ€§èƒ½é€‰åˆ°â€œä¸é‚£ä¹ˆå¯èƒ½â€çš„è¾“å‡ºã€‚</p><p>å› ä¸ºäººç±»æ€ç»´æœ¬èº«ä¹Ÿæ˜¯<code>è·³è·ƒ</code>çš„ã€‚</p><p>è€ƒè™‘ä¸¤ä¸ªè¾“å‡ºä¸‹ä¸€ä¸ªtokenæ—¶çš„æç«¯æƒ…å†µï¼š</p><!-- --> | <!-- --> | <!-- --> | <!-- -->
<p>------- | ------- | ------- | -------
çº¯éšæœºï¼Œæ‰€æœ‰å¯é€‰è¯çš„æ¦‚ç‡æ˜¯å‡ç­‰çš„ | æ¯«æ— æ„ä¹‰ | <code>max entropy</code> | åˆ›é€ æ€§é«˜
greedy sampling | æ¯«æ— ç”Ÿè¶£ | <code>minimum entropy</code> | å¯é¢„æµ‹æ€§é«˜</p><p>å®ç°æ–¹å¼ï¼š<code>softmax temperature</code></p><p>é™¤ä¸€ä¸ª<code>æ¸©åº¦</code>ï¼Œå¦‚æœæ¸©åº¦å¤§äº1ï¼Œé‚£ä¹ˆæ¸©åº¦è¶Šå¤§ï¼Œè¢«é™¤æ•°ç¼©å¹…åº¦å°±è¶Šå¤§ï¼ˆè¿™æ ·æ¸©å·®å°±è¶Šå°ï¼Œåˆ†å¸ƒä¼šæ›´å¹³å‡ï¼‰-&gt; åå‘äº†çº¯éšæœºçš„æ¦‚ç‡ç»“æ„ï¼ˆå‡ç­‰ï¼‰</p><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="k">def</span> <span class="nf">reweight_distribution</span><span class="p">(</span><span class="n">original_distribution</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="n">distribution</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">original_distribution</span><span class="p">)</span> <span class="o">/</span> <span class="n">temperature</span>
    <span class="n">distribution</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">distribution</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">distribution</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">distribution</span><span class="p">)</span>
</pre></div>
<p>å†™æˆå…¬å¼
$
\frac{e^{\frac{log(d)}{T}}}{\sum e^{\frac{log(d)}{T}}}
$
è¿™æ˜¯å¯¹æ¸©åº¦å’Œsigmoidåšäº†èåˆï¼š</p><ol>
<li>ä¸€ä¸ªæ˜¯å¯¹ç›®æ ‡åˆ†å¸ƒå–è‡ªç„¶å¯¹æ•°åé™¤æ¸©åº¦å†å½“æˆeçš„æŒ‡æ•°ç»™å¹‚å›å»ï¼ˆå¦‚æœä¸é™¤æ¸©åº¦ï¼Œé‚£å°±æ˜¯å…ˆlogå†eï¼Œç­‰äºæ˜¯åŸæ•°ï¼‰</li>
<li>æ ‡å‡†çš„sigmoidæ–¹ç¨‹</li>
</ol>
<blockquote>
<p>è¿™é‡Œå›é¡¾ä¸€ä¸ªæ¦‚å¿µï¼šSampling from a space</p></blockquote>
<p>ä¹¦é‡Œå¤§é‡ç”¨äº†è¿™ä¸ªæ¦‚å¿µï¼Œç»“åˆä»£ç ï¼Œå…¶å®å°±æ˜¯ä¸€ä¸ªpredictå‡½æ•°ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä¸€èˆ¬äººç†è§£çš„â€œ<code>é¢„æµ‹ï¼Œæ¨ç†</code>â€ï¼Œæ˜¯ä»ä¸šåŠ¡é€»è¾‘æ–¹é¢æ¥ç†è§£ï¼Œä½œè€…æ›´æ„¿æ„ä»ç»Ÿè®¡å­¦å’Œçº¿æ€§ä»£æ•°è§’åº¦æ¥ç†è§£ã€‚</p><p>ä¸¤ç§è®­ç»ƒæ–¹æ³•ï¼š</p><ol>
<li>æ¯æ¬¡ç”¨Nä¸ªå­—ï¼Œæ¥é¢„æµ‹ç¬¬N+1ä¸ªå­—ï¼Œå³outputåªæœ‰1ä¸ª(voc_size, 1)ï¼Œè®­ç»ƒçš„æ˜¯language model</li>
<li>æ¯æ¬¡ç”¨Nä¸ªå­—(a, b), æ¥é¢„æµ‹(a+1, b+1)ï¼Œ outputæœ‰Nä¸ª(voc_size, N)ï¼Œè®­ç»ƒçš„æ˜¯ç‰¹å®šçš„ä»»åŠ¡ï¼Œæ¯”å¦‚å†™è¯—ï¼Œä½œéŸ³ä¹</li>
</ol>
<p>è¿‡ç¨‹ï¼š</p><ol>
<li>å‡†å¤‡æ•°æ®ï¼ŒXä¸ºä¸€ç»„å¥å­ï¼ŒYä¸ºæ¯ä¸€ä¸ªå¥å­å¯¹åº”çš„ä¸‹ä¸€ä¸ªå­—ï¼ˆå…¨éƒ¨å‘é‡åŒ–ï¼‰</li>
<li>æ­å»ºä¸€ä¸ªLSTM + Dense çš„ç½‘ç»œï¼Œè¾“å‡ºæ ¹æ®å…·ä½“æƒ…å†µè¦ä¹ˆä¸º1ï¼Œè¦ä¹ˆä¸ºN</li>
<li>æ¯ä¸€ä¸ªepoché‡Œå‡è¿›è¡Œé¢„æµ‹ï¼ˆå¦‚æœä¸æ˜¯ä¸ºäº†çœ‹è¿‡ç¨‹ï¼Œæœ‰å¿…è¦å—ï¼Ÿæˆ‘ä»¬è¦æœ€åä¸€è½®çš„é¢„æµ‹ä¸å°±è¡Œäº†ï¼Ÿï¼‰<ul>
<li>è¿›è¡Œä¸€æ¬¡fit(å°±æ˜¯train)ï¼Œå¾—åˆ°ä¼˜åŒ–åçš„å‚æ•°</li>
<li>éšæœºå–ä¸€æ®µæ–‡æœ¬ï¼Œç”¨ä½œç§å­ï¼ˆç”¨æ¥ç”Ÿæˆç¬¬ä¸€ä¸ªå­—ï¼‰</li>
<li>è®¡ç®—ç”Ÿæˆå¤šå°‘ä¸ªå­—ï¼Œå°±å¼€å§‹forå¾ªç¯<ul>
<li>å‘é‡åŒ–å½“å‰çš„ç§å­ï¼ˆä¼šè¶Šæ¥è¶Šé•¿ï¼‰</li>
<li>predictï¼Œå¾—åˆ°æ¯ä¸ªå­—çš„æ¦‚ç‡</li>
<li>softmax temperatureï¼Œå¹³æ»‘æ¦‚ç‡ï¼Œå–å‡ºnext_token</li>
<li>next_tokenè½¬å›æ–‡æœ¬ï¼Œé™„åŠ åˆ°seedåé¢</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3>DeepDream</h3>
<p>çœ‹äº†ä¸€éï¼Œä¸æ„Ÿå…´è¶£ã€‚æ ¸å¿ƒæ€è·¯è·Ÿè§†è§‰åŒ–filterçš„æ€è·¯æ˜¯ä¸€æ ·çš„ï¼š<code>gradient ascent</code></p><ol>
<li>ä»å¯¹æ¯ä¸ªlayeré‡Œçš„å•ä¸ªfilteråšæ¢¯åº¦ä¸Šå‡å˜æˆäº†å¯¹æ•´ä¸ªlayeråšæ¢¯åº¦ä¸Šå‡</li>
<li>ä¸å†ä»éšæœºå™ªå£°å¼€å§‹ï¼Œè€Œæ˜¯ä»ä¸€å¼ çœŸå®å›¾ç‰‡å¼€å§‹ï¼Œå®ç°è¿™äº›layeré‡Œå¯¹å›¾ç‰‡å½±å“æœ€å¤§çš„patternsçš„distorting</li>
</ol>
<h3>Neural style transfer</h3>
<p>Neural style transfer consists of applying the <code>style</code> of a reference image to a target image while conserving the <code>content</code> of the target image.</p><ul>
<li>ä¸¤ä¸ªå¯¹è±¡ï¼š<code>reference</code>, <code>target</code> image</li>
<li>ä¸¤ä¸ªæ¦‚å¿µï¼š<code>style</code>å’Œ<code>content</code></li>
</ul>
<p>å¯¹<code>B</code>çš„contentåº”ç”¨<code>A</code>çš„styleï¼Œæˆ‘ä»¬å¯ä»¥ç†è§£ä¸ºâ€œç¬”åˆ·â€ï¼Œæˆ–è€…ç”¨å‰äº›å¹´çš„æµè¡Œåº”ç”¨æ¥è§£é‡Šï¼šæŠŠä¸€å‰¯ç”»æ°´å½©åŒ–ï¼Œæˆ–æ²¹ç”»åŒ–ã€‚</p><p>æŠŠstyleåˆ†è§£ä¸ºä¸åŒspatial scalesä¸Šçš„ï¼šçº¹ç†ï¼Œé¢œè‰²ï¼Œå’Œvisual pattern</p><p>æƒ³ç”¨æ·±åº¦å­¦ä¹ æ¥å°è¯•è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œé¦–å…ˆè‡³å°‘å¾—å®šä¹‰æŸå¤±å‡½æ•°æ˜¯ä»€ä¹ˆæ ·çš„ã€‚</p><p>If we were able to mathematically define <code>content</code> and <code>style</code>, then an appropriate loss function to minimize would be the following:</p><div class="highlight"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">distance</span><span class="p">(</span><span class="n">style</span><span class="p">(</span><span class="n">reference_image</span><span class="p">)</span> <span class="o">-</span> <span class="n">style</span><span class="p">(</span><span class="n">generated_image</span><span class="p">))</span> <span class="o">+</span>
        <span class="n">distance</span><span class="p">(</span><span class="n">content</span><span class="p">(</span><span class="n">original_image</span><span class="p">)</span> <span class="o">-</span> <span class="n">content</span><span class="p">(</span><span class="n">generated_image</span><span class="p">))</span>
</pre></div>
<p>å³å¯¹æ–°å›¾è€Œè¨€ï¼Œ<code>çº¹ç†è¦æ— é™é è¿‘Aï¼Œå†…å®¹è¦æ— é™é è¿‘B</code>ã€‚</p><ul>
<li>the content loss<ul>
<li>å›¾åƒå†…å®¹å±äºé«˜çº§æŠ½è±¡ï¼Œå› æ­¤åªéœ€è¦top layerså‚ä¸å°±è¡Œäº†ï¼Œå®é™…åº”ç”¨ä¸­åªå–äº†æœ€é¡¶å±‚</li>
</ul>
</li>
<li>the style loss<ul>
<li>åº”ç”¨<code>Gram matrix</code><ul>
<li>the inner product of the feature maps of a given layer</li>
<li>correlations between the layer's feature</li>
<li>éœ€è¦ç”Ÿæˆå›¾å’Œå‚è€ƒå›¾çš„æ¯ä¸€ä¸ªå¯¹åº”çš„layeræ‹¥æœ‰ç›¸åŒçš„çº¹ç†(same <code>textures</code> at different <code>spatial scales</code>)ï¼Œå› æ­¤éœ€è¦æ‰€æœ‰çš„layerå‚ä¸</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>ä»è¿™é‡Œåº”è¯¥ä¹Ÿèƒ½åˆ¤æ–­å‡ºè¦æ­å»ºç½‘ç»œçš„è¯ï¼Œinputè‡³å°‘ç”±ä¸‰éƒ¨åˆ†ï¼ˆä¸‰å¼ å›¾ç‰‡ï¼‰æ„æˆäº†ã€‚</p><p><strong>demo</strong></p><ul>
<li>inputä¸ºå‚è€ƒå›¾ï¼Œç›®æ ‡å›¾ï¼Œå’Œç”Ÿæˆå›¾ï¼ˆå ä½ï¼‰ï¼Œconcatenateæˆä¸€ä¸ªtensor</li>
<li>ç”¨VGG19æ¥åšç‰¹å¾æå–</li>
<li>è®¡ç®—loss<ol>
<li>ç”¨ç”Ÿæˆå›¾å’Œ<code>ç›®æ ‡å›¾</code>çš„<code>top_layer</code>ä»¥L2 normè·ç¦»åšloss</li>
<li>ç”¨ç”Ÿæˆå›¾å’Œ<code>å‚è€ƒå›¾</code>çš„<code>every</code> layerä»¥L2 Normåšlosså¹¶ç´¯åŠ </li>
<li>å¯¹ç”Ÿæˆå›¾åç§»1åƒç´ åšregularization lossï¼ˆå…·ä½“çœ‹ä¹¦ï¼‰</li>
<li>ä¸Šè¿°ä¸‰ç»„lossç´¯åŠ ï¼Œä¸ºä¸€è½®çš„loss</li>
</ol>
</li>
<li>ç”¨lossè®¡ç®—å¯¹input(å³ä¸‰è”å›¾)çš„æ¢¯åº¦</li>
</ul>
<h2>Generating images</h2>
<blockquote>
<p>Sampling from a latent space of images to create entirely new images</p></blockquote>
<p>ç†Ÿæ‚‰çš„å¥å¼åˆæ¥äº†ã€‚</p><p>æ ¸å¿ƒæ€æƒ³ï¼š</p><ol>
<li>low-dimensional <code>latent space</code> of representations<ul>
<li>ä¸€èˆ¬æ˜¯ä¸ªvector space</li>
<li>any point can be mapped to a realistic-looking image</li>
</ul>
</li>
<li>the module capable of <code>realizing this mapping</code>, can take point as input, then output an image, this called:<ul>
<li>generator -&gt; GAN</li>
<li>decoder -&gt; VAE</li>
</ul>
</li>
</ol>
<p>VAE v.s. GAN</p><ul>
<li>VAEs are great for learning latent spaces that are <code>well structured</code></li>
<li>GANs generate images that can potentially be <code>highly realistic</code>, but the latent space they come from may not have as much structure and continuity.</li>
</ul>
<h3>VAEï¼ˆvariational autoencodersï¼‰</h3>
<p>given a <code>latent space</code> of representations, or an embedding space, <code>certain directions</code> in the space <strong>may</strong> encode interesting axes of variation in the original data. -&gt; inspired by <code>concept space</code></p><p>æ¯”å¦‚åŒ…å«äººè„¸çš„æ•°æ®é›†çš„latent spaceé‡Œï¼Œæ˜¯å¦ä¼šå­˜åœ¨<code>smile vectors</code>ï¼Œå®šä½è¿™æ ·çš„vectorï¼Œå°±å¯ä»¥ä¿®æ”¹å›¾ç‰‡ï¼Œè®©å®ƒprojectingåˆ°è¿™ä¸ªlatent spaceé‡Œå»ã€‚</p><p><strong>Variational autoencoders</strong></p><p>Variational autoencoders are a kind of <em>generative model</em> thatâ€™s especially appropriate for the task of <strong>image editing</strong> via concept vectors.</p><p>Theyâ€™re a modern take on <code>autoencoders</code> (a type of network that aims to <code>encode</code>an input to a <code>low-dimensional</code> latent space and then decode it back) that mixes ideas from deep learning with <strong>Bayesian inference</strong>.</p><ul>
<li>VAEæŠŠå›¾ç‰‡è§†ä½œéšè—ç©ºé—´çš„å‚æ•°è¿›è¡Œç»Ÿè®¡è¿‡ç¨‹çš„ç»“æœã€‚</li>
<li>å‚æ•°å°±æ˜¯è¡¨ç¤ºä¸€ç§æ­£æ€åˆ†å¸ƒçš„meanå’Œvarianceï¼ˆå®é™…å–çš„log_variance)</li>
<li>ç”¨è¿™ä¸ªåˆ†å¸ƒå¯ä»¥è¿›è¡Œé‡‡æ ·(sample)</li>
<li>æ˜ å°„å›original image</li>
</ul>
<ol>
<li>An encoder module turns the input samples <em>input_img</em> into two parameters in a latent space of representations, <code>z_mean</code> and <code>z_log_variance</code>.</li>
<li>You randomly sample a point z from the latent normal distribution thatâ€™s assumed to generate the input image, via $z = z_mean + e^{z_log_variance} \times \epsilon$, where $\epsilon$ is a random tensor of small values.</li>
<li>A decoder module maps <em>this point</em> in the latent space back to the original input image.</li>
</ol>
<blockquote>
<p>Because epsilon is random, the process ensures that every point thatâ€™s <strong>close to the latent location</strong> where you encoded input_img (z-mean) can be decoded to something <strong>similar</strong> to input_img, thus forcing the latent space to be continuously meaningful.</p></blockquote>
<ol>
<li>æ‰€ä»¥VAEç”Ÿæˆçš„å›¾ç‰‡æ˜¯å¯è§£é‡Šçš„ï¼Œæ¯”å¦‚åœ¨latent spaceä¸­è·ç¦»ç›¸è¿‘çš„ä¸¤ç‚¹ï¼Œdecodeå‡ºæ¥çš„å›¾ç‰‡ç›¸ä¼¼åº¦ä¹Ÿå°±å¾ˆé«˜ã€‚</li>
<li>å¤šç”¨äºç¼–è¾‘å›¾ç‰‡ï¼Œå¹¶ä¸”èƒ½ç”ŸæˆåŠ¨ç”»è¿‡ç¨‹ï¼ˆå› ä¸ºæ˜¯è¿ç»­çš„ï¼‰</li>
</ol>
<p>ä¼ªä»£ç (ä¸ç®—ï¼Œå¯ä»¥è¯´æ˜¯éª¨å¹²ä»£ç ï¼‰ï¼š</p><div class="highlight"><pre><span></span><span class="n">z_mean</span><span class="p">,</span> <span class="n">z_log_variance</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_img</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">z_mean</span> <span class="o">+</span> <span class="n">exp</span><span class="p">(</span><span class="n">z_log_variance</span><span class="p">)</span> <span class="o">*</span> <span class="n">epsilon</span>  <span class="c1"># sampling</span>
<span class="n">reconstructed_img</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">input_img</span><span class="p">,</span> <span class="n">reconstructed_img</span><span class="p">)</span>
</pre></div>
<p>VAE encoder network</p><div class="highlight"><pre><span></span><span class="n">img_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">input_img</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">shape_before_flattening</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">z_mean</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">z_log_var</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
<ol>
<li>å¯è§æ˜¯ä¸€ä¸ªæ ‡å‡†çš„multi-headçš„ç½‘ç»œ</li>
<li>å¯è§æ‰€è°“çš„latent spaceï¼Œå…¶å®å°±æ˜¯transformingåçš„ç»“æœ</li>
<li>encodeçš„ç›®çš„æ˜¯å›å½’å‡ºä¸¤ä¸ªå‚æ•°ï¼ˆæœ¬ä¾‹æ˜¯ä¸¤ä¸ª2ç»´å‚æ•°ï¼‰</li>
<li>ä¸¤ä¸ªå‚æ•°ä¸€ä¸ªç†è§£ä¸ºmean, ä¸€ä¸ªç†è§£ä¸ºlog_variance</li>
</ol>
<p>decoderè¿‡ç¨‹å°±æ˜¯å¯¹meanå’Œvaréšæœºé‡‡æ ·ï¼ˆå¾—åˆ°z)ï¼Œç„¶åä¸æ–­ä¸Šé‡‡æ ·(<code>Conv2DTranspose</code>)å¾—åˆ°å½¢çŠ¶ä¸æºå›¾ä¸€è‡´çš„è¾“å‡º(å¾—åˆ°z_decode)çš„è¿‡ç¨‹ã€‚</p><ol>
<li>z_decodeè·ŸzåšBCE loss</li>
<li>è¿˜è¦åŠ ä¸€ä¸ªregularization lossé˜²æ­¢overfitting</li>
</ol>
<blockquote>
<p>æ­¤å¤„è¯·çœ‹ä¹¦ï¼Œæ¼”ç¤ºäº†è‡ªå®šä¹‰çš„lossã€‚å› ä¸ºkerasé«˜åº¦å°è£…ï¼Œæ‰€ä»¥å„ç§åœ¨å°è£…ä¹‹å¤–çš„è‡ªå®šä¹‰çš„ç”¨æ³•å°¤å…¶å€¼å¾—å…³æ³¨ã€‚æ¯”å¦‚è¿™é‡Œï¼Œè‡ªå®šä¹‰äº†lossä¹‹åï¼ŒModelå’Œfité‡Œå°±ä¸éœ€è¦ä¼ Yï¼Œcompileæ—¶ä¹Ÿä¸éœ€è¦ä¼ lossäº†ã€‚</p></blockquote>
<blockquote>
<p>lossæ˜¯åœ¨æœ€åä¸€å±‚layeré‡Œè®¡ç®—çš„ï¼Œå¹¶ä¸”é€šè¿‡ä¸€ä¸ªlayeræ–¹æ³•<code>add_loss</code>ï¼ŒæŠŠlosså’Œinputé€šçŸ¥ç»™äº†networkï¼ˆå¦‚æœä½ æƒ³çŸ¥é“æ³¨å…¥ç‚¹çš„è¯ï¼‰</p></blockquote>
<p>ä½¿ç”¨æ¨¡å‹çš„è¯ï¼Œå°±æ˜¯ç”Ÿæˆä¸¤ç»„éšæœºæ•°ï¼Œå½“æˆmeanå’Œlog_varianceï¼Œè§‚å¯Ÿdecodeä¹‹åçš„ç»“æœã€‚</p><h3>GAN</h3>
<p><code>Generative adversarial network</code>å¯ä»¥åˆ›ä½œä»¥å‡ä¹±çœŸçš„å›¾ç‰‡ã€‚é€šè¿‡è®­ç»ƒæœ€å¥½çš„é€ å‡å’Œå’Œæœ€å¥½çš„é‰´åˆ«è€…æ¥è¾¾åˆ°â€œåˆ›é€ â€è¶Šæ¥è¶Šé€¼è¿‘äººç±»åˆ›ä½œçš„ä½œå“ã€‚</p><ul>
<li><strong>Generator</strong> network: Takes as input a random vector (a random point in the latent space), and decodes it into a synthetic image</li>
<li><strong>Discriminator</strong> network (or adversary): Takes as input an image (real or synthetic), and predicts whether the image came from the training set or was created by the generator network.</li>
</ul>
<p><strong>deep convolutional GAN (DCGAN)</strong></p><ul>
<li>a GAN where the generator and discriminator are deep convnets.</li>
<li>In particular, it uses a <code>Conv2DTranspose</code> layer for image upsampling in the generator.</li>
</ul>
<p>è®­ç»ƒç”Ÿæˆå™¨æ˜¯å†²ç€èƒ½è®©é‰´åˆ«å™¨å°½å¯èƒ½é‰´åˆ«ä¸ºçœŸçš„æ–¹å‘çš„ï¼šthe generator is trained to <code>fool</code> the discriminatorã€‚</p><blockquote>
<p>è¿™å¥è¯å…¶å®æš—å«äº†ä¸€ä¸ªå‰æï¼Œä¸‹é¢ä¼šè¯´ï¼Œå°±æ˜¯æ­¤æ—¶discriminatoræ˜¯ç¡®å®šçš„ã€‚å³åœ¨ç¡®å®šçš„é‰´åˆ«èƒ½åŠ›ä¸‹ï¼Œå°½å¯èƒ½å»æ‹Ÿåˆgeneratorçš„è¾“å‡ºï¼Œè®©å®ƒèƒ½é€šè¿‡å½“å‰é‰´åˆ«å™¨çš„æµ‹è¯•ã€‚</p></blockquote>
<p>ä¹¦ä¸­è¯´è®­ç»ƒDCGANå¾ˆå¤æ‚ï¼Œè€Œä¸”å¾ˆå¤štrick, è¶…å‚é çš„æ˜¯ç»éªŒè€Œä¸æ˜¯ç†è®ºæ”¯æ’‘ï¼Œæ‘˜æŠ„å¹¶ç¬”è®°a bag of trickså¦‚ä¸‹ï¼š</p><ul>
<li>We use <code>tanh</code> as the last activation in the generator, instead of sigmoid, which is more commonly found in other types of models.</li>
<li>We sample points from the latent space using a <code>normal distribution</code> (Gaussian distribution), not a uniform distribution.</li>
<li>Stochasticity is good to induce robustness. Because GAN training results in a dynamic equilibrium, GANs are likely to get stuck in all sorts of ways. Introducing randomness during training helps prevent this. We introduce randomness in two ways:<ul>
<li>by using <code>dropout</code> in the discriminator</li>
<li>and by adding <code>random noise</code> to the labels for the discriminator.</li>
</ul>
</li>
<li>Sparse gradients can hinder GAN training. In deep learning, sparsity is often a desirable property, <strong>but not in GANs</strong>. Two things can induce gradient sparsity: <code>max pooling</code> operations and <code>ReLU</code> activations.<ul>
<li>Instead of max pooling, we recommend using <code>strided convolutions</code> for downsampling(ç”¨æ­¥é•¿å·ç§¯ä»£æ›¿pooling),</li>
<li>and we recommend using a <code>LeakyReLU</code> layer instead of a ReLU activation. Itâ€™s similar to ReLU, but it relaxes sparsity constraints by allowing small negative activation values.</li>
</ul>
</li>
<li>In generated images, itâ€™s common to see <code>checkerboard artifacts</code>(stirdeå’Œkernel sizeä¸åŒ¹é…åƒä¸‡çš„) caused by unequal coverage of the pixel space in the generator.<ul>
<li>To fix this, we use a kernel size thatâ€™s divisible by the stride size whenever we use a strided <code>Conv2DTranpose</code> or Conv2D in both the generator and the discriminator.</li>
</ul>
</li>
</ul>
<p><strong>Train</strong></p><ol>
<li>Draw random points in the latent space (random noise).</li>
<li>Generate images with generator using this random noise.</li>
<li>Mix the generated images with real ones.</li>
<li>Train discriminator using these mixed images, with corresponding targets:<ul>
<li>either â€œrealâ€ (for the real images) or â€œfakeâ€ (for the generated images).</li>
<li>æ‰€ä»¥é‰´åˆ«å™¨æ˜¯<code>å•ç‹¬è®­ç»ƒçš„</code>ï¼ˆå‰é¢ç¬”è®°é“ºå«è¿‡äº†ï¼‰</li>
<li>ä¸‹é¢å°±æ˜¯trainæ•´ä¸ªDCGANäº†ï¼š</li>
</ul>
</li>
<li>Draw new random points in the latent space.</li>
<li>Train gan using these random vectors, with targets that all say â€œthese are real images.â€ This updates the weights of the generator (only, because the discriminator is frozen inside gan) to move them toward getting the discriminator to predict â€œthese are real imagesâ€ for generated images: this trains the generator to fool the discriminator.<ul>
<li>åªtrainç½‘ç»œé‡Œçš„generator</li>
<li>discriminatorä¸è®­ç»ƒï¼Œå› ä¸ºæ˜¯è¦ç”¨â€œå·²ç»è®­ç»ƒåˆ°ç›®å‰ç¨‹åº¦çš„â€discriminatoræ¥åšä¸‹é¢çš„ä»»åŠ¡</li>
<li>ä»»åŠ¡å°±æ˜¯åªé€å…¥ä¼ªé€ å›¾ï¼Œå¹¶å£°æ˜æ‰€æœ‰å›¾éƒ½æ˜¯çœŸçš„ï¼Œå»è®©generatorç”Ÿæˆèƒ½é€¼è¿‘è¿™ä¸ªå£°æ˜çš„å›¾</li>
<li>generatorå°±æ˜¯è¿™ä¹ˆè®­ç»ƒå‡ºæ¥çš„ã€‚</li>
<li>æ‰€ä»¥å®é™…ä»£ç æ˜¯ä¸€æ¬¡epochæ˜¯ç”±trainä¸€ä¸ª<code>discriminator</code>å’Œtrainä¸€ä¸ª<code>GAN</code>ç»„æˆ.</li>
</ul>
</li>
</ol>
<p>å› ä¸ºé‰´åˆ«å™¨å’Œç”Ÿæˆå™¨æ˜¯ä¸€èµ·è®­ç»ƒçš„ï¼Œå› æ­¤å‰å‡ è½®ç”Ÿæˆçš„è‚¯å®šæ˜¯å™ªéŸ³ï¼Œä½†å‰å‡ è½®é‰´åˆ«å™¨ä¹Ÿæ˜¯çé‰´åˆ«çš„ã€‚</p>
            </div>
        </article>
        <div class="prism-post-meta col-md-8 offset-md-2">
    <span>walker</span>
    
    <span>/</span>
    <span>
        <a class="category no-link" href="/category/posts/" target="_self">
        posts
        </a>
    </span>
    
    
    <span>/</span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/deep%20learning/" target="_self">#deep learning</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" target="_self">#æ·±åº¦å­¦ä¹ </a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/keras/" target="_self">#keras</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/cv/" target="_self">#cv</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/nlp/" target="_self">#nlp</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/tensorflow/" target="_self">#tensorflow</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/gan/" target="_self">#gan</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/lstm/" target="_self">#lstm</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/language%20mode/" target="_self">#language mode</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/rnn/" target="_self">#rnn</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/heatmap/" target="_self">#heatmap</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/dropout/" target="_self">#dropout</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/machine%20learning/" target="_self">#machine learning</a>
    </span>
    
    
    
    <span>/</span>
    <span class="leancloud_visitors" id="/archives/Deep-Learning-with-Python-Notes-7/" data-flag-title="ã€ŠDeep Learning with Pythonã€‹ç¬”è®°[7]"><span class="leancloud-visitors-count"></span> Views</span>
    
</div>
    </section>

    
<section id="prism__pagination" class="prism-pagination" class="col-md-8 offset-md-2">
    <ul>
        
        <li class="next">
            <a class="no-link" href="/archives/%E6%9D%8E%E5%AE%8F%E6%AF%85Machine-Learning-2021-Spring-1/" target="_self" title="æå®æ¯…Machine Learning 2021 Springç¬”è®°[1]"><i class="fa fa-chevron-left" aria-hidden="true"></i>Newer</a>
        </li>
        
        
        <li class="prev">
            <a class="no-link" href="/archives/Deep-Learning-with-Python-Notes-6/" target="_self" title="ã€ŠDeep Learning with Pythonã€‹ç¬”è®°[6]">Older<i class="fa fa-chevron-right" aria-hidden="true"></i></a>
        </li>
        
    </ul>
</section>


    
    <script>
        var initValine = function() {
            new Valine({"enable": true, "el": "#vcomments", "appId": "7tP92LoqK2cggW61DvJmWBo0-gzGzoHsz", "appKey": "iQCtrtlr8eKrQllM03GMESMJ", "visitor": true, "recordIP": true});
        }

    </script>
    <script defer src='https://cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js' onload="initValine()"></script>
    <div class="prism-comment-section container" id="prism__comment">
        <div class="row">
            <div class="col-md-8 offset-md-2">
                <div id="vcomments"></div>
            </div>
        </div>
    </div>
    

</main>

            <footer id="prism__footer">
                <section>
                    <div>
                        <nav class="social-links">
                            <ul><li><a class="no-link" title="Twitter" href="https://twitter.com/walkerwzy" target="_blank" rel="noopener noreferrer nofollow"><i class="gi gi-twitter"></i></a></li><li><a class="no-link" title="GitHub" href="https://github.com/walkerwzy" target="_blank" rel="noopener noreferrer nofollow"><i class="gi gi-github"></i></a></li><li><a class="no-link" title="Weibo" href="https://weibo.com/1071696872" target="_blank" rel="noopener noreferrer nofollow"><i class="gi gi-weibo"></i></a></li></ul>
                        </nav>
                    </div>

                    <section id="prism__external_links">
                        <ul>
                            
                            <li>
                                <a class="no-link" target="_blank" href="https://github.com/AlanDecode/Maverick" rel="noopener noreferrer nofollow">Maverick</a>ï¼šğŸ„â€ Go My Own Way.
                                <span>|</span>
                            </li>
                            
                            <li>
                                <a class="no-link" target="_blank" href="https://www.imalan.cn" rel="noopener noreferrer nofollow">Triple NULL</a>ï¼šHome page for AlanDecode.
                                <span>|</span>
                            </li>
                            
                        </ul>
                    </section>

                    <div class="copyright">
                        <p class="copyright-text">
                            <span class="brand">walker's code blog</span>
                            <span>Copyright Â© 2022 AlanDecode</span>
                        </p>
                        <p class="copyright-text powered-by">
                            | Powered by <a href="https://github.com/AlanDecode/Maverick" class="no-link" target="_blank" rel="noopener noreferrer nofollow">Maverick</a> | Theme <a href="https://github.com/Reedo0910/Maverick-Theme-Prism" target="_blank" class="no-link" rel="noopener noreferrer nofollow">Prism</a>
                        </p>
                    </div>
                    <div class="footer-addon">
                        
                    </div>
                </section>
                <script>
                    var site_build_date = "2019-12-06T12:00+08:00"

                </script>
                <script src="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/prism-efa8685153.js"></script>
            </footer>
        </div>
    </div>
    </div>

    <script src="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/ExSearch/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/ExSearch/ExSearch-493cb9cd89.js"></script>

    <!--katex-->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/katex.min.js"></script>
    <script>
        mathOpts = {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "\\[", right: "\\]", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false }
            ]
        };

    </script>
    <script defer src="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/auto-render.min.js" onload="renderMathInElement(document.body, mathOpts);"></script>

    
</body>

</html>